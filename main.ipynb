{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep fake detection challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup tensorflow to use GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "gpu = True\n",
    "# Use gpu if available\n",
    "if gpu:\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    for gpu in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "    print(os.environ['CUDA_VISIBLE_DEVICES'])  # Check the value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup the seed for random number generators to ensure reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Procesing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "\n",
    "- Load the data from the directory\n",
    "- Extract 20 random frames from each video\n",
    "- Use MTcnn to detect faces in the frames. If no face is detected, discard the frame. If more than one face is detected, take the first face since both faces have been faked similarly.\n",
    "- Resize the frames to 224x224\n",
    "- Save the frames in a new directory and create a new image_label.json file\n",
    "\n",
    "This step takes a long time (174 min running on a Tesla V100-PCIE-32GB GPU).\n",
    "Therefore we do this only once and save the processed images to a new directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping processing: 'data_images' folder is already populated.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import imageio\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "# Paths\n",
    "data_folder = \"data\"\n",
    "output_folder = \"data_images\"\n",
    "\n",
    "# If the output folder is not empty, skip processing\n",
    "if os.path.exists(output_folder) and len(os.listdir(output_folder)) > 0:\n",
    "    print(\"Skipping processing: 'data_images' folder is already populated.\")\n",
    "else:\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "    # Initialize MTCNN\n",
    "    detector = MTCNN()\n",
    "\n",
    "    # Parameters\n",
    "    num_frames = 20\n",
    "    frame_size = (224, 224)\n",
    "\n",
    "    # Load labels from the existing metadata\n",
    "    with open(\"data/metadata.json\", \"r\") as f:\n",
    "        video_labels = json.load(f)\n",
    "\n",
    "    # Dictionary to store image-label mappings\n",
    "    image_labels = {}\n",
    "\n",
    "    # Process videos\n",
    "    for video_name in os.listdir(data_folder):\n",
    "        video_path = os.path.join(data_folder, video_name)\n",
    "\n",
    "        if video_name.endswith(\".mp4\"):\n",
    "            reader = imageio.get_reader(video_path, \"ffmpeg\")\n",
    "            total_frames = reader.count_frames()\n",
    "\n",
    "            # Select frame indices\n",
    "            selected_frame_indices = sorted(random.sample(range(total_frames), num_frames))\n",
    "\n",
    "            # Extract frames and process\n",
    "            for i, frame in enumerate(reader):\n",
    "                if i in selected_frame_indices:\n",
    "                    frame_rgb = frame\n",
    "                    if frame.ndim == 2:  # if grayscale\n",
    "                        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB)\n",
    "                    elif frame.shape[2] == 4:  # if RGBA\n",
    "                        frame_rgb = frame[:, :, :3]\n",
    "                    # Detect faces in the frame and choose the first face\n",
    "                    faces = detector.detect_faces(frame)\n",
    "                    \n",
    "                    # If no faces are found, skip this frame\n",
    "                    if len(faces) == 0:\n",
    "                        continue\n",
    "\n",
    "                    # Get the bounding box of the first face\n",
    "                    face = faces[0]\n",
    "                    x, y, w, h = face['box']\n",
    "\n",
    "                    # Crop the face region\n",
    "                    face_crop = frame[y:y+h, x:x+w]\n",
    "                    \n",
    "                    if face_crop.size == 0:  # Ensure the cropped face is valid\n",
    "                        continue\n",
    "                    \n",
    "                    # Resize the cropped face to 224x224\n",
    "                    face_resized = cv2.resize(face_crop, frame_size)\n",
    "\n",
    "                    # Generate a unique image name for the face\n",
    "                    image_name = f\"{video_name.split('.')[0]}_{i}.jpg\"\n",
    "                    image_path = os.path.join(output_folder, image_name)\n",
    "\n",
    "                    # Save the resized face image\n",
    "                    cv2.imwrite(image_path, face_resized)\n",
    "\n",
    "                    # Store the label mapping\n",
    "                    video_metadata = video_labels.get(video_name)\n",
    "                    if video_metadata:\n",
    "                        image_labels[image_name] = video_metadata[\"label\"]\n",
    "\n",
    "            reader.close()\n",
    "\n",
    "    # Save the label mappings to a JSON file\n",
    "    with open(\"image_labels.json\", \"w\") as f:\n",
    "        json.dump(image_labels, f, indent=4)\n",
    "\n",
    "    print(\"Processing complete. Images saved in 'data_images', labels in 'image_labels.json'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Label Counts Plot\n",
    "- The plot above visualizes the count of `REAL` and `FAKE` videos that have been processed in the pre-processing step. Keep in mind that the number of images is 20 times the number of videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_labels = json.load(open(\"image_labels.json\", \"r\"))\n",
    "\n",
    "movie_labels = {}\n",
    "\n",
    "for filename, label in image_labels.items():\n",
    "    movie_name = filename.split(\"_\")[0]  # Extract movie name\n",
    "    movie_labels[movie_name] = label  # Store only one label per movie\n",
    "    \n",
    "# Count the number of unique REAL and FAKE videos\n",
    "real_movies_count = sum(1 for label in movie_labels.values() if label == \"REAL\")\n",
    "fake_movies_count = sum(1 for label in movie_labels.values() if label == \"FAKE\")\n",
    "\n",
    "# Plotting the results\n",
    "labels = ['REAL', 'FAKE']\n",
    "counts = [real_movies_count, fake_movies_count]\n",
    "\n",
    "plt.bar(labels, counts, color=['green', 'red'])\n",
    "plt.xlabel('Video Type')\n",
    "plt.ylabel('Count')\n",
    "plt.title('REAL vs FAKE Video Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "- Assign the videos to fakes and reals classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the images and labels and set it to a tf.data.Dataset\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fakes = np.empty((0, 2), dtype=object)\n",
    "reals = np.empty((0, 2), dtype=object)\n",
    "\n",
    "for image, label in movie_labels.items():\n",
    "    if label == \"FAKE\":\n",
    "        \n",
    "        fakes = np.append(fakes, np.array([[image, label]]), axis=0)\n",
    "    else:\n",
    "        reals = np.append(reals, np.array([[image, label]]), axis=0)\n",
    "        \n",
    "data = np.vstack((fakes, reals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perorm train-test split on the movies while stratifying on the labels. This is very important to spit by the videos and not by the frames to avoid data leakage between the train and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=SEED, stratify=data[:, 1])\n",
    "\n",
    "train, val = train_test_split(train, test_size=0.2, random_state=SEED, stratify=train[:, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since we split by the videos we need to assign the corresponding images to the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to sets for quick lookup\n",
    "train_movies = set(train[:, 0])\n",
    "val_movies = set(val[:, 0])\n",
    "test_movies = set(test[:, 0])\n",
    "\n",
    "# Function to filter images based on movie set\n",
    "def get_images_from_movies(movie_set, image_labels):\n",
    "    return np.array([[img, label] for img, label in image_labels.items() if img.split(\"_\")[0] in movie_set], dtype=object)\n",
    "\n",
    "# Filter images for each dataset\n",
    "train_images = get_images_from_movies(train_movies, image_labels)\n",
    "val_images = get_images_from_movies(val_movies, image_labels)\n",
    "test_images = get_images_from_movies(test_movies, image_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the total number of images in each class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "\n",
    "unique_labels, label_counts = np.unique(train_images[:, 1], return_counts=True)\n",
    "axes[0].bar(unique_labels, label_counts, edgecolor='black')\n",
    "axes[0].set_xticks(unique_labels)\n",
    "axes[0].set_xticklabels(['Fakes', 'Real'])\n",
    "axes[0].set_xlabel('Label')\n",
    "axes[0].set_ylabel('Number of Images')\n",
    "axes[0].set_title('Number of Images per Label in Training Set')\n",
    "\n",
    "unique_labels, label_counts = np.unique(val_images[:, 1], return_counts=True)\n",
    "axes[1].bar(unique_labels, label_counts, edgecolor='black')\n",
    "axes[1].set_xticks(unique_labels)\n",
    "axes[0].set_xticklabels(['Fakes', 'Real'])\n",
    "axes[1].set_xlabel('Label')\n",
    "axes[1].set_ylabel('Number of Images')\n",
    "axes[1].set_title('Number of Images per Label in Validation Set')\n",
    "\n",
    "unique_labels, label_counts = np.unique(test_images[:, 1], return_counts=True)\n",
    "axes[2].bar(unique_labels, label_counts, edgecolor='black')\n",
    "axes[2].set_xticks(unique_labels)\n",
    "axes[0].set_xticklabels(['Fakes', 'Real'])\n",
    "axes[2].set_xlabel('Label')\n",
    "axes[2].set_ylabel('Number of Images')\n",
    "axes[2].set_title('Number of Images per Label in Test Set')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the images under train, test and val folders with the respective labels in the folder name\n",
    "\n",
    "Mapping the labels to integers:\n",
    "\n",
    "REAL → 0\n",
    "\n",
    "FAKE → 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Mapping labels\n",
    "label_mapping = {\"REAL\": 0, \"FAKE\": 1}\n",
    "\n",
    "\n",
    "def save_images(data, base_folder):\n",
    "    if not os.path.exists(base_folder):\n",
    "        os.makedirs(base_folder)\n",
    "    for img_path, label in data:\n",
    "        # Convert label to 0 or 1\n",
    "        numeric_label = label_mapping[label]\n",
    "        \n",
    "        label_folder = os.path.join(base_folder, str(numeric_label))\n",
    "        if not os.path.exists(label_folder):\n",
    "            os.makedirs(label_folder)\n",
    "        img = Image.open(\"data_images/\" + img_path)\n",
    "        img.save(os.path.join(label_folder, os.path.basename(img_path)))\n",
    "\n",
    "if os.path.exists('train') and os.path.exists('val') and os.path.exists('test') and len(os.listdir(output_folder)) > 0:\n",
    "    print(\"Skipping processing: 'train, val, test' folder is already full.\")\n",
    "else:\n",
    "    # Save the images for each dataset\n",
    "    save_images(train_images, 'train')\n",
    "    save_images(val_images, 'val')\n",
    "    save_images(test_images, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSIM Masks\n",
    "\n",
    "### Take the mean of all the real images from the train dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Calculate average real image for SSIM ---\n",
    "real_train_dir = os.path.join('train', '0')  # Assuming '0' is REAL class\n",
    "real_image_files = [os.path.join(real_train_dir, f) for f in os.listdir(real_train_dir)]\n",
    "\n",
    "# Compute average of all real training images\n",
    "avg_real_image = np.zeros((224, 224), dtype=np.float32)\n",
    "for img_file in real_image_files:\n",
    "    img = cv2.imread(img_file, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        avg_real_image += img.astype(np.float32)\n",
    "avg_real_image /= len(real_image_files)\n",
    "avg_real_image = avg_real_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this average image and calculate the SSIM between this and all the images in the dataset and save the SSIM values in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def precompute_ssim_masks(dataset_dir, save_dir, avg_real_image):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    for label in os.listdir(dataset_dir):\n",
    "        label_dir = os.path.join(dataset_dir, label)\n",
    "        label_save_dir = os.path.join(save_dir, label)\n",
    "        os.makedirs(label_save_dir, exist_ok=True)  # Create label directory\n",
    "\n",
    "        for img_file in os.listdir(label_dir):\n",
    "            img_path = os.path.join(label_dir, img_file)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (224, 224))\n",
    "\n",
    "                # Compute SSIM map\n",
    "                _, ssim_map = ssim(img, avg_real_image, full=True)\n",
    "\n",
    "               # Normalize to [0,1] and save as float32 numpy array\n",
    "                ssim_map = (ssim_map - ssim_map.min()) / (ssim_map.max() - ssim_map.min())\n",
    "                mask_path = os.path.join(label_save_dir, f\"{os.path.splitext(img_file)[0]}.npy\")\n",
    "                np.save(mask_path, ssim_map.astype(np.float32))\n",
    "                \n",
    "# Precompute SSIM masks for each dataset\n",
    "if os.path.exists('train_ssim') and os.path.exists('val_ssim') and os.path.exists('test_ssim'):\n",
    "    print(\"Skipping processing: 'train_ssim, val_ssim, test_ssim' folder is already full.\")\n",
    "else:\n",
    "    # Save the images for each dataset\n",
    "    precompute_ssim_masks(\"train\", 'train_ssim', avg_real_image)\n",
    "    precompute_ssim_masks(\"val\", 'val_ssim', avg_real_image)\n",
    "    precompute_ssim_masks(\"test\", 'test_ssim', avg_real_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the images from the folders and perform data augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4936 images belonging to 2 classes.\n",
      "Found 1220 images belonging to 2 classes.\n",
      "Found 1516 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 16\n",
    "# Create ImageDataGenerators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,              # Normalize pixel values to [0, 1]\n",
    "    rotation_range=10,           # Randomly rotate images by up to 10 degrees\n",
    "    width_shift_range=0.1,       # Randomly shift images horizontally by 10% of the width\n",
    "    height_shift_range=0.1,      # Randomly shift images vertically by 10% of the height\n",
    "    shear_range=0.2,             # Apply shearing transformations\n",
    "    zoom_range=0.1,              # Randomly zoom in or out by 20%\n",
    "    horizontal_flip=True,        # Randomly flip images horizontally\n",
    "    fill_mode='nearest'          # Fill missing pixels after transformations,\n",
    "\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'train',                   \n",
    "    target_size=(224, 224),     \n",
    "    batch_size=batch_size,              \n",
    "    class_mode='binary'    \n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    'val', \n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'test', \n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a dual data generator to include the SSIM Masks as an additional input to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dual_input_generator(base_gen, ssim_dir):\n",
    "    while True:\n",
    "        batch_x, batch_y = next(base_gen)\n",
    "\n",
    "        batch_ssim = []\n",
    "        for img_path in base_gen.filepaths:  # Use full filepaths\n",
    "            # Get corresponding SSIM mask path\n",
    "            rel_path = os.path.relpath(img_path, base_gen.directory)\n",
    "            mask_path = os.path.join(ssim_dir, os.path.splitext(rel_path)[0] + '.npy')\n",
    "            \n",
    "            # Load SSIM mask\n",
    "            ssim_map = np.load(mask_path)\n",
    "            ssim_map = cv2.resize(ssim_map, (224, 224))  # Ensure correct size\n",
    "            ssim_map = np.expand_dims(ssim_map, axis=-1)  # Add channel dimension\n",
    "            batch_ssim.append(ssim_map)\n",
    "        \n",
    "        yield [batch_x, np.array(batch_ssim)], batch_y\n",
    "\n",
    "# Create final generators\n",
    "train_generator_dual = dual_input_generator(train_generator, 'train_ssim')\n",
    "val_generator_dual = dual_input_generator(val_generator, 'val_ssim')\n",
    "test_generator_dual = dual_input_generator(test_generator, 'test_ssim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed class weights: {0: 2.5183673469387755, 1: 0.6238624873609707}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.array([0, 1]), y=train_generator.classes)\n",
    "\n",
    "# Convert to dictionary format for Keras\n",
    "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "print(\"Computed class weights:\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightweight Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 192, 192, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 96, 96, 16)   432         ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 96, 96, 16)   64          ['Conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 96, 96, 16)   0           ['bn_Conv1[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 96, 96, 16)  144         ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 96, 96, 16)  64          ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 96, 96, 16)  0           ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                                                           ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 96, 96, 8)   128         ['expanded_conv_depthwise_relu[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 96, 96, 8)   32          ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 96, 96, 48)   384         ['expanded_conv_project_BN[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 96, 96, 48)  192         ['block_1_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 96, 96, 48)   0           ['block_1_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 97, 97, 48)   0           ['block_1_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 48, 48, 48)  432         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 48, 48, 48)  192         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 48, 48, 48)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 48, 48, 16)   768         ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 48, 48, 16)  64          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 48, 48, 96)   1536        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 48, 48, 96)  384         ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 48, 48, 96)   0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 48, 48, 96)  864         ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 48, 48, 96)  384         ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 48, 48, 96)   0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 48, 48, 16)   1536        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 48, 48, 16)  64          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 48, 48, 16)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 48, 48, 96)   1536        ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 48, 48, 96)  384         ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)     (None, 48, 48, 96)   0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 49, 49, 96)   0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 24, 24, 96)  864         ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 24, 24, 96)  384         ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 24, 24, 96)   0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 24, 24, 16)   1536        ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 24, 24, 16)  64          ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 24, 24, 96)   1536        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 24, 24, 96)  384         ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 24, 24, 96)   0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 24, 24, 96)  864         ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 24, 24, 96)  384         ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 24, 24, 96)   0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 24, 24, 16)   1536        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 24, 24, 16)  64          ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 24, 24, 16)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 24, 24, 96)   1536        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 24, 24, 96)  384         ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 24, 24, 96)   0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 24, 24, 96)  864         ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 24, 24, 96)  384         ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 24, 24, 96)   0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 24, 24, 16)   1536        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 24, 24, 16)  64          ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 24, 24, 16)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 24, 24, 96)   1536        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 24, 24, 96)  384         ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 24, 24, 96)   0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 25, 25, 96)   0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 12, 12, 96)  864         ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 12, 12, 96)  384         ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 12, 12, 96)   0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 12, 12, 32)   3072        ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 12, 12, 32)  128         ['block_6_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 12, 12, 192)  6144        ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 12, 12, 192)  768        ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 12, 12, 192)  0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 12, 12, 192)  1728       ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 12, 12, 192)  768        ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 12, 12, 192)  0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 12, 12, 32)   6144        ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 12, 12, 32)  128         ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 12, 12, 32)   0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 12, 12, 192)  6144        ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 12, 12, 192)  768        ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 12, 12, 192)  0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 12, 12, 192)  1728       ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 12, 12, 192)  768        ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 12, 12, 192)  0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 12, 12, 32)   6144        ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 12, 12, 32)  128         ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 12, 12, 32)   0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 12, 12, 192)  6144        ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 12, 12, 192)  768        ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 12, 12, 192)  0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 12, 12, 192)  1728       ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 12, 12, 192)  768        ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 12, 12, 192)  0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 12, 12, 32)   6144        ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 12, 12, 32)  128         ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 12, 12, 32)   0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 12, 12, 192)  6144        ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 12, 12, 192)  768        ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 12, 12, 192)  0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 12, 12, 192)  1728       ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 12, 12, 192)  768        ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 12, 12, 192)  0          ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 12, 12, 48)   9216        ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 12, 12, 48)  192         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 12, 12, 288)  13824       ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 12, 12, 288)  1152       ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 12, 12, 288)  0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 12, 12, 288)  2592       ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 12, 12, 288)  1152       ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 12, 12, 288)  0          ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 12, 12, 48)   13824       ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 12, 12, 48)  192         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 12, 12, 48)   0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 12, 12, 288)  13824       ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 12, 12, 288)  1152       ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 12, 12, 288)  0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 12, 12, 288)  2592       ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 12, 12, 288)  1152       ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 12, 12, 288)  0          ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 12, 12, 48)   13824       ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 12, 12, 48)  192         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 12, 12, 48)   0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 12, 12, 288)  13824       ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 12, 12, 288)  1152       ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 12, 12, 288)  0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 13, 13, 288)  0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 6, 6, 288)   2592        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 6, 6, 288)   1152        ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 6, 6, 288)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 6, 6, 80)     23040       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 6, 6, 80)    320         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 6, 6, 480)    38400       ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 6, 6, 480)   1920        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 6, 6, 480)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_14_depthwise (DepthwiseC  (None, 6, 6, 480)   4320        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 6, 6, 480)   1920        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 6, 6, 480)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 6, 6, 80)     38400       ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 6, 6, 80)    320         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 6, 6, 80)     0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 6, 6, 480)    38400       ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 6, 6, 480)   1920        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 6, 6, 480)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 6, 6, 480)   4320        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 6, 6, 480)   1920        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 6, 6, 480)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 6, 6, 80)     38400       ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 6, 6, 80)    320         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 6, 6, 80)     0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 6, 6, 480)    38400       ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 6, 6, 480)   1920        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 6, 6, 480)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 6, 6, 480)   4320        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 6, 6, 480)   1920        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None, 192, 192, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 6, 6, 480)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 190, 190, 16  160         ['input_10[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 6, 6, 160)    76800       ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 95, 95, 16)  0           ['conv2d_14[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 6, 6, 160)   640         ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 93, 93, 32)   4640        ['max_pooling2d_11[0][0]']       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 6, 6, 1280)   204800      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d_12 (MaxPooling2D  (None, 46, 46, 32)  0           ['conv2d_15[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 6, 6, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 44, 44, 64)   18496       ['max_pooling2d_12[0][0]']       \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 6, 6, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_13 (MaxPooling2D  (None, 22, 22, 64)  0           ['conv2d_16[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_average_pooling2d_3 (Gl  (None, 1280)        0           ['out_relu[0][0]']               \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 30976)        0           ['max_pooling2d_13[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 32256)        0           ['global_average_pooling2d_3[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            32257       ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 761,777\n",
      "Trainable params: 55,553\n",
      "Non-trainable params: 706,224\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2  # Smaller than EfficientNet\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Concatenate, GlobalAveragePooling2D, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 1. MobileNet branch (RGB images) - Much smaller than EfficientNet\n",
    "rgb_input = Input(shape=(192, 192, 3))  # Reduced resolution\n",
    "model = MobileNetV2(include_top=False, \n",
    "                       weights='imagenet', \n",
    "                       input_tensor=rgb_input,\n",
    "                       alpha=0.5)  # Width multiplier (0.5 makes it smaller)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False  # Freeze for transfer learning\n",
    "\n",
    "rgb_features = GlobalAveragePooling2D()(model.output)  # (1280,)\n",
    "\n",
    "# 2. Simplified SSIM branch\n",
    "ssim_input = Input(shape=(192, 192, 1))  # Match reduced resolution\n",
    "\n",
    "x = Conv2D(16, (3,3), activation='relu')(ssim_input)\n",
    "x = MaxPooling2D(2)(x)  # 96x96\n",
    "\n",
    "x = Conv2D(32, (3,3), activation='relu')(x)\n",
    "x = MaxPooling2D(2)(x)  # 48x48\n",
    "\n",
    "x = Conv2D(64, (3,3), activation='relu')(x)\n",
    "x = MaxPooling2D(2)(x)  # 24x24\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "# 3. Combine features\n",
    "combined = Concatenate()([rgb_features, x])\n",
    "\n",
    "# 4. Classification head\n",
    "output = Dense(1, activation='sigmoid')(combined)\n",
    "\n",
    "model = Model(inputs=[rgb_input, ssim_input], outputs=output)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define callbacks\n",
    "checkpoint_cb = ModelCheckpoint(\"best_model.h5\", \n",
    "                                monitor=\"val_loss\", \n",
    "                                save_best_only=True, \n",
    "                                mode=\"min\", \n",
    "                                verbose=1)\n",
    "\n",
    "early_stopping_cb = EarlyStopping(monitor=\"val_loss\", \n",
    "                                  patience=5,  # Stop if val_loss doesn't improve for 5 epochs\n",
    "                                  restore_best_weights=True, \n",
    "                                  verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 945. MiB for an array with shape (4936, 224, 224, 1) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator_dual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use original generator's length\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator_dual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# Use original generator's length\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_cb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\engine\\data_adapter.py:927\u001b[0m, in \u001b[0;36mGeneratorDataAdapter._standardize_batch.<locals>._convert_dtype\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_dtype\u001b[39m(t):\n\u001b[0;32m    924\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\n\u001b[0;32m    925\u001b[0m         t\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, np\u001b[38;5;241m.\u001b[39mfloating\n\u001b[0;32m    926\u001b[0m     ):\n\u001b[1;32m--> 927\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloatx\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 945. MiB for an array with shape (4936, 224, 224, 1) and data type float32"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator_dual,\n",
    "    steps_per_epoch=len(train_generator),  # Use original generator's length\n",
    "    validation_data=val_generator_dual,\n",
    "    validation_steps=len(val_generator),   # Use original generator's length\n",
    "    epochs=2,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " rescaling_2 (Rescaling)        (None, 224, 224, 3)  0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " normalization_1 (Normalization  (None, 224, 224, 3)  7          ['rescaling_2[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " rescaling_3 (Rescaling)        (None, 224, 224, 3)  0           ['normalization_1[0][0]']        \n",
      "                                                                                                  \n",
      " stem_conv_pad (ZeroPadding2D)  (None, 225, 225, 3)  0           ['rescaling_3[0][0]']            \n",
      "                                                                                                  \n",
      " stem_conv (Conv2D)             (None, 112, 112, 32  864         ['stem_conv_pad[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stem_bn (BatchNormalization)   (None, 112, 112, 32  128         ['stem_conv[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stem_activation (Activation)   (None, 112, 112, 32  0           ['stem_bn[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1a_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['stem_activation[0][0]']        \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " block1a_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1a_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block1a_activation (Activation  (None, 112, 112, 32  0          ['block1a_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block1a_se_squeeze (GlobalAver  (None, 32)          0           ['block1a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block1a_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block1a_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block1a_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block1a_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1a_activation[0][0]',     \n",
      "                                )                                 'block1a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block1a_project_conv (Conv2D)  (None, 112, 112, 16  512         ['block1a_se_excite[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1a_project_bn (BatchNorma  (None, 112, 112, 16  64         ['block1a_project_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " block2a_expand_conv (Conv2D)   (None, 112, 112, 96  1536        ['block1a_project_bn[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block2a_expand_bn (BatchNormal  (None, 112, 112, 96  384        ['block2a_expand_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block2a_expand_activation (Act  (None, 112, 112, 96  0          ['block2a_expand_bn[0][0]']      \n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " block2a_dwconv_pad (ZeroPaddin  (None, 113, 113, 96  0          ['block2a_expand_activation[0][0]\n",
      " g2D)                           )                                ']                               \n",
      "                                                                                                  \n",
      " block2a_dwconv (DepthwiseConv2  (None, 56, 56, 96)  864         ['block2a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block2a_bn (BatchNormalization  (None, 56, 56, 96)  384         ['block2a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2a_activation (Activation  (None, 56, 56, 96)  0           ['block2a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2a_se_squeeze (GlobalAver  (None, 96)          0           ['block2a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2a_se_reshape (Reshape)   (None, 1, 1, 96)     0           ['block2a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2a_se_reduce (Conv2D)     (None, 1, 1, 4)      388         ['block2a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2a_se_expand (Conv2D)     (None, 1, 1, 96)     480         ['block2a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_se_excite (Multiply)   (None, 56, 56, 96)   0           ['block2a_activation[0][0]',     \n",
      "                                                                  'block2a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_project_conv (Conv2D)  (None, 56, 56, 24)   2304        ['block2a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_project_bn (BatchNorma  (None, 56, 56, 24)  96          ['block2a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2b_expand_conv (Conv2D)   (None, 56, 56, 144)  3456        ['block2a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_expand_bn (BatchNormal  (None, 56, 56, 144)  576        ['block2b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block2b_expand_activation (Act  (None, 56, 56, 144)  0          ['block2b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block2b_dwconv (DepthwiseConv2  (None, 56, 56, 144)  1296       ['block2b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block2b_bn (BatchNormalization  (None, 56, 56, 144)  576        ['block2b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2b_activation (Activation  (None, 56, 56, 144)  0          ['block2b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2b_se_squeeze (GlobalAver  (None, 144)         0           ['block2b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2b_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block2b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block2b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block2b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_se_excite (Multiply)   (None, 56, 56, 144)  0           ['block2b_activation[0][0]',     \n",
      "                                                                  'block2b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_project_conv (Conv2D)  (None, 56, 56, 24)   3456        ['block2b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_project_bn (BatchNorma  (None, 56, 56, 24)  96          ['block2b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2b_drop (Dropout)         (None, 56, 56, 24)   0           ['block2b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_add (Add)              (None, 56, 56, 24)   0           ['block2b_drop[0][0]',           \n",
      "                                                                  'block2a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_expand_conv (Conv2D)   (None, 56, 56, 144)  3456        ['block2b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block3a_expand_bn (BatchNormal  (None, 56, 56, 144)  576        ['block3a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3a_expand_activation (Act  (None, 56, 56, 144)  0          ['block3a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block3a_dwconv_pad (ZeroPaddin  (None, 59, 59, 144)  0          ['block3a_expand_activation[0][0]\n",
      " g2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " block3a_dwconv (DepthwiseConv2  (None, 28, 28, 144)  3600       ['block3a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block3a_bn (BatchNormalization  (None, 28, 28, 144)  576        ['block3a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3a_activation (Activation  (None, 28, 28, 144)  0          ['block3a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3a_se_squeeze (GlobalAver  (None, 144)         0           ['block3a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3a_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block3a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block3a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block3a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_se_excite (Multiply)   (None, 28, 28, 144)  0           ['block3a_activation[0][0]',     \n",
      "                                                                  'block3a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_project_conv (Conv2D)  (None, 28, 28, 40)   5760        ['block3a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_project_bn (BatchNorma  (None, 28, 28, 40)  160         ['block3a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3b_expand_conv (Conv2D)   (None, 28, 28, 240)  9600        ['block3a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_expand_bn (BatchNormal  (None, 28, 28, 240)  960        ['block3b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3b_expand_activation (Act  (None, 28, 28, 240)  0          ['block3b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block3b_dwconv (DepthwiseConv2  (None, 28, 28, 240)  6000       ['block3b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block3b_bn (BatchNormalization  (None, 28, 28, 240)  960        ['block3b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3b_activation (Activation  (None, 28, 28, 240)  0          ['block3b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3b_se_squeeze (GlobalAver  (None, 240)         0           ['block3b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3b_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block3b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block3b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block3b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_se_excite (Multiply)   (None, 28, 28, 240)  0           ['block3b_activation[0][0]',     \n",
      "                                                                  'block3b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_project_conv (Conv2D)  (None, 28, 28, 40)   9600        ['block3b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_project_bn (BatchNorma  (None, 28, 28, 40)  160         ['block3b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3b_drop (Dropout)         (None, 28, 28, 40)   0           ['block3b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_add (Add)              (None, 28, 28, 40)   0           ['block3b_drop[0][0]',           \n",
      "                                                                  'block3a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_expand_conv (Conv2D)   (None, 28, 28, 240)  9600        ['block3b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4a_expand_bn (BatchNormal  (None, 28, 28, 240)  960        ['block4a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4a_expand_activation (Act  (None, 28, 28, 240)  0          ['block4a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4a_dwconv_pad (ZeroPaddin  (None, 29, 29, 240)  0          ['block4a_expand_activation[0][0]\n",
      " g2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " block4a_dwconv (DepthwiseConv2  (None, 14, 14, 240)  2160       ['block4a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block4a_bn (BatchNormalization  (None, 14, 14, 240)  960        ['block4a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4a_activation (Activation  (None, 14, 14, 240)  0          ['block4a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4a_se_squeeze (GlobalAver  (None, 240)         0           ['block4a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4a_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block4a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block4a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block4a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_se_excite (Multiply)   (None, 14, 14, 240)  0           ['block4a_activation[0][0]',     \n",
      "                                                                  'block4a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_project_conv (Conv2D)  (None, 14, 14, 80)   19200       ['block4a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4b_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block4b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4b_expand_activation (Act  (None, 14, 14, 480)  0          ['block4b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4b_dwconv (DepthwiseConv2  (None, 14, 14, 480)  4320       ['block4b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4b_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block4b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4b_activation (Activation  (None, 14, 14, 480)  0          ['block4b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4b_se_squeeze (GlobalAver  (None, 480)         0           ['block4b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block4b_activation[0][0]',     \n",
      "                                                                  'block4b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_project_conv (Conv2D)  (None, 14, 14, 80)   38400       ['block4b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4b_drop (Dropout)         (None, 14, 14, 80)   0           ['block4b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_add (Add)              (None, 14, 14, 80)   0           ['block4b_drop[0][0]',           \n",
      "                                                                  'block4a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4c_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block4c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4c_expand_activation (Act  (None, 14, 14, 480)  0          ['block4c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4c_dwconv (DepthwiseConv2  (None, 14, 14, 480)  4320       ['block4c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4c_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block4c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4c_activation (Activation  (None, 14, 14, 480)  0          ['block4c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4c_se_squeeze (GlobalAver  (None, 480)         0           ['block4c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block4c_activation[0][0]',     \n",
      "                                                                  'block4c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_project_conv (Conv2D)  (None, 14, 14, 80)   38400       ['block4c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4c_drop (Dropout)         (None, 14, 14, 80)   0           ['block4c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_add (Add)              (None, 14, 14, 80)   0           ['block4c_drop[0][0]',           \n",
      "                                                                  'block4b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5a_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5a_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block5a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5a_expand_activation (Act  (None, 14, 14, 480)  0          ['block5a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5a_dwconv (DepthwiseConv2  (None, 14, 14, 480)  12000      ['block5a_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5a_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block5a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5a_activation (Activation  (None, 14, 14, 480)  0          ['block5a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5a_se_squeeze (GlobalAver  (None, 480)         0           ['block5a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block5a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block5a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block5a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block5a_activation[0][0]',     \n",
      "                                                                  'block5a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_project_conv (Conv2D)  (None, 14, 14, 112)  53760       ['block5a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5b_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block5b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5b_expand_activation (Act  (None, 14, 14, 672)  0          ['block5b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5b_dwconv (DepthwiseConv2  (None, 14, 14, 672)  16800      ['block5b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5b_bn (BatchNormalization  (None, 14, 14, 672)  2688       ['block5b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5b_activation (Activation  (None, 14, 14, 672)  0          ['block5b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5b_se_squeeze (GlobalAver  (None, 672)         0           ['block5b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5b_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_se_excite (Multiply)   (None, 14, 14, 672)  0           ['block5b_activation[0][0]',     \n",
      "                                                                  'block5b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_project_conv (Conv2D)  (None, 14, 14, 112)  75264       ['block5b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5b_drop (Dropout)         (None, 14, 14, 112)  0           ['block5b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_add (Add)              (None, 14, 14, 112)  0           ['block5b_drop[0][0]',           \n",
      "                                                                  'block5a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5c_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block5c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5c_expand_activation (Act  (None, 14, 14, 672)  0          ['block5c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5c_dwconv (DepthwiseConv2  (None, 14, 14, 672)  16800      ['block5c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5c_bn (BatchNormalization  (None, 14, 14, 672)  2688       ['block5c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5c_activation (Activation  (None, 14, 14, 672)  0          ['block5c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5c_se_squeeze (GlobalAver  (None, 672)         0           ['block5c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5c_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_se_excite (Multiply)   (None, 14, 14, 672)  0           ['block5c_activation[0][0]',     \n",
      "                                                                  'block5c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_project_conv (Conv2D)  (None, 14, 14, 112)  75264       ['block5c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5c_drop (Dropout)         (None, 14, 14, 112)  0           ['block5c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_add (Add)              (None, 14, 14, 112)  0           ['block5c_drop[0][0]',           \n",
      "                                                                  'block5b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6a_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6a_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block6a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6a_expand_activation (Act  (None, 14, 14, 672)  0          ['block6a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6a_dwconv_pad (ZeroPaddin  (None, 17, 17, 672)  0          ['block6a_expand_activation[0][0]\n",
      " g2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " block6a_dwconv (DepthwiseConv2  (None, 7, 7, 672)   16800       ['block6a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6a_bn (BatchNormalization  (None, 7, 7, 672)   2688        ['block6a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6a_activation (Activation  (None, 7, 7, 672)   0           ['block6a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6a_se_squeeze (GlobalAver  (None, 672)         0           ['block6a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6a_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block6a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6a_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block6a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6a_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block6a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_se_excite (Multiply)   (None, 7, 7, 672)    0           ['block6a_activation[0][0]',     \n",
      "                                                                  'block6a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_project_conv (Conv2D)  (None, 7, 7, 192)    129024      ['block6a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6b_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6b_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6b_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6b_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6b_activation (Activation  (None, 7, 7, 1152)  0           ['block6b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6b_se_squeeze (GlobalAver  (None, 1152)        0           ['block6b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6b_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6b_activation[0][0]',     \n",
      "                                                                  'block6b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6b_drop (Dropout)         (None, 7, 7, 192)    0           ['block6b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_add (Add)              (None, 7, 7, 192)    0           ['block6b_drop[0][0]',           \n",
      "                                                                  'block6a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6c_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6c_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6c_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6c_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6c_activation (Activation  (None, 7, 7, 1152)  0           ['block6c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6c_se_squeeze (GlobalAver  (None, 1152)        0           ['block6c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6c_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6c_activation[0][0]',     \n",
      "                                                                  'block6c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6c_drop (Dropout)         (None, 7, 7, 192)    0           ['block6c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_add (Add)              (None, 7, 7, 192)    0           ['block6c_drop[0][0]',           \n",
      "                                                                  'block6b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6d_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6d_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6d_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6d_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6d_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6d_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6d_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6d_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6d_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6d_activation (Activation  (None, 7, 7, 1152)  0           ['block6d_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6d_se_squeeze (GlobalAver  (None, 1152)        0           ['block6d_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6d_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6d_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6d_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6d_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6d_activation[0][0]',     \n",
      "                                                                  'block6d_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6d_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6d_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6d_drop (Dropout)         (None, 7, 7, 192)    0           ['block6d_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_add (Add)              (None, 7, 7, 192)    0           ['block6d_drop[0][0]',           \n",
      "                                                                  'block6c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block7a_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6d_add[0][0]']            \n",
      "                                                                                                  \n",
      " block7a_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block7a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block7a_expand_activation (Act  (None, 7, 7, 1152)  0           ['block7a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block7a_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  10368       ['block7a_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block7a_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block7a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 224, 224, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " block7a_activation (Activation  (None, 7, 7, 1152)  0           ['block7a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 224, 224, 32  320         ['input_4[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block7a_se_squeeze (GlobalAver  (None, 1152)        0           ['block7a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 112, 112, 32  0           ['conv2d_2[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block7a_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block7a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 112, 112, 64  18496       ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block7a_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block7a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " block7a_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block7a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 56, 56, 128)  73856       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " block7a_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block7a_activation[0][0]',     \n",
      "                                                                  'block7a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 128)  0          ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " block7a_project_conv (Conv2D)  (None, 7, 7, 320)    368640      ['block7a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 28, 28, 256)  295168      ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " block7a_project_bn (BatchNorma  (None, 7, 7, 320)   1280        ['block7a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 256)  0          ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " top_conv (Conv2D)              (None, 7, 7, 1280)   409600      ['block7a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 14, 14, 512)  1180160     ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " top_bn (BatchNormalization)    (None, 7, 7, 1280)   5120        ['top_conv[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 7, 7, 512)   0           ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " top_activation (Activation)    (None, 7, 7, 1280)   0           ['top_bn[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 7, 7, 1280)   656640      ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 7, 7, 2560)   0           ['top_activation[0][0]',         \n",
      "                                                                  'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2560)        0           ['concatenate_1[0][0]']          \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            2561        ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,276,772\n",
      "Trainable params: 2,227,201\n",
      "Non-trainable params: 4,049,571\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Concatenate, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 1. EfficientNet branch (RGB images)\n",
    "rgb_input = Input(shape=(224, 224, 3))\n",
    "base_model = EfficientNetB0(include_top=False, weights='imagenet', input_tensor=rgb_input)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False  # Freeze EfficientNet layers for transfer learning\n",
    "\n",
    "rgb_features = base_model.output  # Shape: (7, 7, 1280)\n",
    "\n",
    "# 2. SSIM branch (Grayscale input)\n",
    "ssim_input = Input(shape=(224, 224, 1))\n",
    "\n",
    "x_ssim = Conv2D(32, (3,3), activation='relu', padding='same')(ssim_input)\n",
    "x_ssim = MaxPooling2D((2,2))(x_ssim)  # (112, 112, 32)\n",
    "\n",
    "x_ssim = Conv2D(64, (3,3), activation='relu', padding='same')(x_ssim)\n",
    "x_ssim = MaxPooling2D((2,2))(x_ssim)  # (56, 56, 64)\n",
    "\n",
    "x_ssim = Conv2D(128, (3,3), activation='relu', padding='same')(x_ssim)\n",
    "x_ssim = MaxPooling2D((2,2))(x_ssim)  # (28, 28, 128)\n",
    "\n",
    "x_ssim = Conv2D(256, (3,3), activation='relu', padding='same')(x_ssim)\n",
    "x_ssim = MaxPooling2D((2,2))(x_ssim)  # (14, 14, 256)\n",
    "\n",
    "x_ssim = Conv2D(512, (3,3), activation='relu', padding='same')(x_ssim)\n",
    "x_ssim = MaxPooling2D((2,2))(x_ssim)  # (7, 7, 512)\n",
    "\n",
    "# Match EfficientNet's output channels\n",
    "x_ssim = Conv2D(1280, (1,1), activation='relu')(x_ssim)  # (7, 7, 1280)\n",
    "\n",
    "# 3. Combine EfficientNet and SSIM features\n",
    "combined = Concatenate()([rgb_features, x_ssim])  # (7, 7, 2560)\n",
    "\n",
    "# 4. Classification head\n",
    "x = GlobalAveragePooling2D()(combined)  # (2560,)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# 5. Model definition\n",
    "model = Model(inputs=[rgb_input, ssim_input], outputs=output)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define callbacks\n",
    "checkpoint_cb = ModelCheckpoint(\"best_model.h5\", \n",
    "                                monitor=\"val_loss\", \n",
    "                                save_best_only=True, \n",
    "                                mode=\"min\", \n",
    "                                verbose=1)\n",
    "\n",
    "early_stopping_cb = EarlyStopping(monitor=\"val_loss\", \n",
    "                                  patience=5,  # Stop if val_loss doesn't improve for 5 epochs\n",
    "                                  restore_best_weights=True, \n",
    "                                  verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/conv2d_2/Relu' defined at (most recent call last):\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 542, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 531, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 775, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3311, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3493, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\shegg\\AppData\\Local\\Temp\\ipykernel_16732\\4011942989.py\", line 1, in <module>\n      history = model.fit(\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 314, in call\n      return self.activation(outputs)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\activations.py\", line 317, in relu\n      return backend.relu(\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\backend.py\", line 5366, in relu\n      x = tf.nn.relu(x)\nNode: 'model/conv2d_2/Relu'\nOOM when allocating tensor with shape[4936,224,224,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv2d_2/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_18956]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator_dual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use original generator's length\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator_dual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# Use original generator's length\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_cb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/conv2d_2/Relu' defined at (most recent call last):\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 542, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 531, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 775, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3311, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3493, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\shegg\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\shegg\\AppData\\Local\\Temp\\ipykernel_16732\\4011942989.py\", line 1, in <module>\n      history = model.fit(\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 314, in call\n      return self.activation(outputs)\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\activations.py\", line 317, in relu\n      return backend.relu(\n    File \"c:\\Users\\shegg\\.conda\\envs\\py310\\lib\\site-packages\\keras\\backend.py\", line 5366, in relu\n      x = tf.nn.relu(x)\nNode: 'model/conv2d_2/Relu'\nOOM when allocating tensor with shape[4936,224,224,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv2d_2/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_18956]"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator_dual,\n",
    "    steps_per_epoch=len(train_generator),  # Use original generator's length\n",
    "    validation_data=val_generator_dual,\n",
    "    validation_steps=len(val_generator),   # Use original generator's length\n",
    "    epochs=2,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
